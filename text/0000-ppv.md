- Feature Name: `minimal_portable_packed_vector_types`
- Start Date: (fill me in with today's date, YYYY-MM-DD)
- RFC PR: (leave this empty)
- Rust Issue: (leave this empty)

# Summary
[summary]: #summary

This RFC adds portable packed SIMD vector types up to 256-bit.

Future RFCs will cover some of the following extensions as they get implemented
in `stdsimd`.

* portable vector shuffles, gathers, and scatters
* boolean vectors, boolean reductions, portable vector comparisons
* 512-bit vector types and masks
* half-float (f16) vectors

# Motivation
[motivation]: #motivation

The `std::arch` module exposes architecture-specific SIMD types like `_m128` - a
128-bit wide SIMD type. How these bits are interpreted depends on the intrinsics
being used. For example, let's sum 8 `f32`s values using the SSE4.1 facilities
in the `std::arch` module. This is one way to do it
([playground](https://play.rust-lang.org/?gist=165e2886b4883ec98d4e8bb4d6a32e22&version=nightly)):

```rust
unsafe fn add_reduce(a: __m128, b: __m128) -> f32 {
    let c = _mm_hadd_ps(a, b);
    let c = _mm_hadd_ps(c, _mm_setzero_ps());
    let c = _mm_hadd_ps(c, _mm_setzero_ps());
    std::mem::transmute(_mm_extract_ps(c, 0))
}

fn main() {
    unsafe {
        let a = _mm_set_ps(1., 2., 3., 4.);
        let b = _mm_set_ps(5., 6., 7., 8.);
        let r = add_reduce(a, b);
        assert_eq!(r, 36.);
    }
}
```

Notice that:

* one has to put some effort to extrapolate with the signature what `add_reduce`
  actually does: "ok, add_reduce, takes 128-bit vectors, returns a `f32`, ah!
  Those 128-bit vectors should probably contain 4 packed f32s!"
  
* it requires a lot of unsafe code: the intrinsics are unsafe, the intrinsic API
  relies on the user performing transmutes

* it requires a lot of architecture specific knowledge: how the intrinsics are
  called, how they are used together
  
* this solution only works on `x86` or `x86_64` with SSE3 enabled.

With portable packed vector types we can do much better
([playground](https://play.rust-lang.org/?gist=7fb4e3b6c711b5feb35533b50315a5fb&version=nightly)):

```rust
fn main() {
    let a = f32x4::new(1., 2., 3., 4.);
    let b = f32x4::new(5., 6., 7., 8.);
    let r = (a + b).sum();
    assert_eq!(r, 36.);
}
```

in both cases, the same code is generated:

```asm
  haddps xmm0, xmm1
  xorps xmm1, xmm1
  haddps xmm0, xmm1
  haddps xmm0, xmm1
```

# Guide-level explanation
[guide-level-explanation]: #guide-level-explanation

This RFC introduces portable packed SIMD vector types and their minimal API. Here:

* portable: is the opposite of architecture-specific. These types work both
  correctly and efficiently on all architectures. They are a zero-overhead
  abstraction, that is, for the operations that these types support, one cannot
  write better code by hand (otherwise it is an implementation bug).
  
* packed: is the opposite of "scalable" or "Cray vectors". That is, these
  vector's have a compile-time fixed length. They can be stored inside structs,
  on the stack, on the heap, passed via ABIs.
  
# Reference-level explanation
[reference-level-explanation]: #reference-level-explanation
  
## Vector types

The vector types are named according to the following scheme:

> {element_type}{element_width}x{number_of_lanes}

where the following element types are introduced by this RFC:

* `i`: signed integer
* `u`: unsigned integer
* `f`: float

So that `u16x8` reads "a SIMD vector of eight packed 16-bit wide unsigned
integers". The width of a vector can be computed by multiplying the
`{element_width}` times the `{number_of_lanes}`. For `u16x8`, 16 x 8 = 128, so
this vector type is 128 bits wide.

> Note: this nomenclature follows closely the nomenclature used by ARM in their
> vector types: <type><size>x<number of lanes>_t

This RFC proposes adding all vector types with sizes in range [16, 256] bit to
the `std::simd` module, that is:

* 16-bit wide vectors:
  * `i8x2`
  * `u8x2`
* 32-bit wide vectors:
  * `i8x4`
  * `u8x4`
  * `i16x2`
  * `u16x2`
* 64-bit wide vectors:
  * `i8x8`
  * `u8x8`
  * `i16x4`
  * `u16x4`
  * `i32x2`
  * `u32x2`
  * `f32x2`
* 128-bit wide vectors:
  * `i8x16`
  * `u8x16`
  * `i16x8`
  * `u16x8`
  * `i32x4`
  * `u32x4`
  * `f32x4`
  * `i64x2`
  * `u64x2`
  * `f64x2`

Note that half-float (`f16`) vectors are not part of this RFC but will need to
be covered by future RFCs extending this one.

## API of portable packed SIMD vector types

### Traits overview

All signed integer, unsigned integer, and floating point vector types implement
the following traits:

* `Copy`
* `Clone`
* `Default`: zero-initializes the vector.
* `Debug`: formats the vector as `({}, {}, ...)`.
* `PartialEq<Self>`: performs a lane-wise comparison between two vectors and
  returns `true` if all lanes compare `true`.
* `PartialOrd<Self>`: performs a lane-wise comparison between two vectors and
  returns `true` if all lanes compare `true`.
* `From`/`Into`/`FromBits`/`IntoBits`: see the [lane-wise casts and bitwise
  conversions](#casts-and-conversions) section below.
* `Add<Output=Self>`, `Sub<Output=Self>`, `Mul<Output=Self>`, 
  `Div<Output=Self>`, `Rem<Output=Self>`, `AddAssign`, `SubAssign`, `MulAssign`, 
  `DivAssign`, `RemAssign`: lane-wise arithmetic operations.

All signed and unsigned integer vectors also implement:

* `Eq`: equivalent to `PartialEq<Self>`
* `Ord`: equivalent to `PartialOrd<Self>`
* `Hash`: equivalent to `Hash` for `[element_type; number_of_elements]`.
* `fmt::LowerHex`: formats the vector as hexadecimal.
* TODO: `fmt::UpperHex`: formats the vector as hexadecimal.
* TODO: `fmt::Octal`: formats the vector as an octal number.
* TODO: `fmt::Binary`: formats the vector as binary number.
* `Not<Output=Self>`,`BitAnd<Output=Self>`, `BitOr<Output=Self>`,
  `BitXor<<Output=Self>`, `BitAndAssign`, `BitOrAssign`,
  `BitXorAssign`: lane-wise bitwise operations.
* `Shl<*>`, `Shr<*>`, `ShlAssign<*>`,`ShrAssign<*>`: shifts for all literal
  integer types.

### Inherent Methods

#### Construction and element access

All portable vector types implement the following methods:

```rust
impl {element_type}{element_width}x{number_of_lanes} {

/// Creates a new instance of the vector from `number_of_lanes` 
/// values.
pub const fn new(args...) -> Self;

/// Returns the number of vector lanes.
pub const fn lanes() -> usize;

/// Constructs a new instance with each element initialized to
/// `value`.
pub const fn splat(value: element_type) -> Self;

/// Extracts the value at `index`.
///
/// # Panics
///
/// If `index >= Self::lanes()`.
pub fn extract(self, index: usize) -> element_type;

/// Extracts the value at `index`.
///
/// If `index >= Self::lanes()` the behavior is undefined.
pub unsafe fn extract_unchecked(self, index: usize) -> element_type;

/// Returns a new vector where the value at `index` is replaced by `new_value`.
///
/// # Panics
///
/// If `index >= Self::lanes()`.
#[must_use = implementation-defined]
pub fn replace(self, index: usize, new_value: $elem_ty) -> Self;

/// Returns a new vector where the value at `index` is replaced by `new_value`.
///
/// # Panics
///
/// If `index >= Self::lanes()`.
#[must_use = implementation-defined]
pub unsafe fn replace_unchecked(self, index: usize, 
                                new_value: element_type) -> Self;

}
```

#### Lane-wise casts and bitwise conversions
[casts-and-conversions]: #casts-and-conversions

The portable vector types implement lane-wise and bitwise casts.

##### Lane-wise casts

Vectors with identical number of lanes can be converted into each other by
performing lane-wise `as` casts provided by the `From` and `Into` traits. 

For example:

```rust
let x = f32x2::new(1., 2.);
let y: f64x2 = x.into();
```

These conversions are provided across all portable vector types having the same
number of lanes.

##### Bitwise casts

To interface with the architecture-specific vector types and intrinsics it is
often required to perform lossless bitwise casts from one type to another.

In an analogous way to the `f32::from_bits` method and the `From` and `Into`
traits, these conversions are performed via the reflexive `FromBits`/`IntoBits`
traits. These conversions have run-time zero-overhead.

For example:

```rust
let x = f32x4::new(1., 2., 3., 4.);
let y: __m128 = x.into_bits();
```

These conversions are provided across all portable vector types of the same
width, and across the portable vector types and the architecture-specific vector
types.

#### Loads and Stores

All portable vector types implement the following methods:

```rust
impl {element_type}{element_width}x{number_of_lanes} {

/// Writes the values of the vector to the `slice`.
///
/// # Panics
///
/// If `slice.len() < Self::lanes()` or `&slice[0]` is not
/// aligned to an `align_of::<Self>()` boundary.
pub fn store_aligned(self, slice: &mut [element_type]);

/// Writes the values of the vector to the `slice`.
///
/// # Panics
///
/// If `slice.len() < Self::lanes()`.
pub fn store_unaligned(self, slice: &mut [element_type]);

/// Writes the values of the vector to the `slice`.
///
/// # Precondition
///
/// If `slice.len() < Self::lanes()` or `&slice[0]` is not
/// aligned to an `align_of::<Self>()` boundary, the behavior is
/// undefined.
pub unsafe fn store_aligned_unchecked(self, slice: &mut [element_type]);

/// Writes the values of the vector to the `slice`.
///
/// # Precondition
///
/// If `slice.len() < Self::lanes()` the behavior is undefined.
pub unsafe fn store_unaligned_unchecked(self, slice: &mut [element_type]);

/// Instantiates a new vector with the values of the `slice`.
///
/// # Panics
///
/// If `slice.len() < Self::lanes()` or `&slice[0]` is not aligned
/// to an `align_of::<Self>()` boundary.
pub fn load_aligned(slice: &[element_type]) -> Self

/// Instantiates a new vector with the values of the `slice`.
///
/// # Panics
///
/// If `slice.len() < Self::lanes()`.
pub fn load_unaligned(slice: &[element_type]) -> Self;

/// Instantiates a new vector with the values of the `slice`.
///
/// # Precondition
///
/// If `slice.len() < Self::lanes()` or `&slice[0]` is not aligned
/// to an `align_of::<Self>()` boundary, the behavior is undefined.
pub unsafe fn load_aligned_unchecked(slice: &[element_type]) -> Self;

/// Instantiates a new vector with the values of the `slice`.
///
/// # Precondition
///
/// If `slice.len() < Self::lanes()` the behavior is undefined.
pub unsafe fn load_unaligned_unchecked(slice: &[element_type]) -> Self;

}
```

#### Arithmetic reductions 

All portable vector types implement the following methods:

```rust
impl {element_type}{element_width}x{number_of_lanes} {

/// Horizontal sum of the vector elements.
pub fn sum(self) -> element_type;

/// Horizontal product of the vector elements.
pub fn product(self) -> element_type;

}
```

##### Semantics for integer vectors

If integer overflow occurs the result is the mathematical result modulo `2^n`. 

##### Semantics for floating point vectors.

The floating-point horizontal reductions are unordered. That is, the reductions
are **not** equivalent to:

```rust
let mut val: f32 = vec.extract(0);
for i in 1..f32x4::lanes() {
    val += vec.extract(i);
}
assert_eq!(val, vec.sum()); // MAYBE FAILS
```

#### Bitwise reductions 

All signed and unsigned integer vectors implement the following methods:

```rust
impl {element_type}{element_width}x{number_of_lanes} {

/// Horizontal bitwise `and` of the vector elements.
pub fn and(self) -> element_type;

/// Horizontal bitwise `or` of the vector elements.
pub fn or(self) -> element_type;

/// Horizontal bitwise `xor` of the vector elements.
pub fn xor(self) -> element_type;

}
```

#### Min/Max reductions

All portable vector types implement the following methods:

```rust
impl {element_type}{element_width}x{number_of_lanes} {
            
/// Value of the largest element in the vector.
pub fn max(self) -> element_type;

/// Value of the smallest element in the vector.
pub fn min(self) -> element_type;

}
```

##### Semantics for floating-point vectors

If the vector contains `NaN`s the result is unspecified. 

# TODO: ABI 

TODO: @acrichto: IIRC currently the Rust ABI for SIMD types always passes
vector types by pointers. This avoids the issues mentioned in:
https://github.com/rust-lang/rust/issues/44367

How exactly this work is pretty important and should be explained here. 

Then we have the issue that SIMD types in `extern` functions might not be sound.
IIRC this is currently disallowed. Is there an issue for this? 

# Drawbacks
[drawbacks]: #drawbacks

The main drawback is that in a future where Rust has multiple backends,
providing this types will take some work. Most backeds support vector types in
one form or another, and if the backend supports the architecture-specific
vector types exposed by `std::arch` chances are that very little work will
actually be required to support this.

# Rationale and alternatives
[alternatives]: #alternatives

TODO: @acrichto: passing vector types on the stack vs on function arguments.

What where the alternatives here? We discussed simd ABIs as a feature, shims,
... and many other things, and they all caused problems with trait methods,
function pointers, etc.

# Prior art
[prior-art]: #prior-art

All of this is implemented in `stdsimd` and can be used on nightly today via the
`std::simd` module. The `stdsimd` crate is an effort started by @burntsushi to
put the `rust-lang-nursery/simd` crate into a state suitable for stabilization.
The `rust-lang-nursery/simd` crate was mainly developed by @huonw and IIRC it is
heavily-inspired by Dart's SIMD which is from where the `f32x4` naming scheme
comes from.

# Unresolved questions
[unresolved]: #unresolved-questions

TBD.
